{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942b4d34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.010172,
     "end_time": "2024-05-04T19:14:39.692853",
     "exception": false,
     "start_time": "2024-05-04T19:14:39.682681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Home Credit Default Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9017cf1",
   "metadata": {
    "papermill": {
     "duration": 0.008054,
     "end_time": "2024-05-04T19:14:39.709621",
     "exception": false,
     "start_time": "2024-05-04T19:14:39.701567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "### The Objective\n",
    "The Home Credit Default Risk project is aimed to predict which clients of loan providers are capable of repaying their loans. Home Credit's goal is the ensure each client has appropriate limits set for principal, maturity, and repayment calendars to empower consumers by identifying repayment abilities.\n",
    "\n",
    "During this project, we are going to explore several files of data to better understand exactly what pre-existing information we have collected for each consumer, analyze trends, and explore various modeling techniques to predict whether or not the client is likely to default on their payments.\n",
    "\n",
    "We found early on that the Gradient Boosted Tree models have consistently outperformed other classification models such as Logistic Regression, Classification Trees, and Random Forest Classifiers. After the inital baseline model, the following submissions are primarily using the Gradient Boosted Tree with variations of new features from supplementary datasets along with created features we have engineered.\n",
    "\n",
    "### The Evaluation\n",
    "We are measuring the success of our predictive models abilities based on the Receiver Operator Characteristic Area Under the Curve, also known as the ROC-AUC score. The primary measurements accounted for in the ROC-AUC metric are the True-Positive predictions and False-Positive Predictions. Scoring is on a 0 to 1 scale, where 1 represents the models ability to perfectly distinguish our target variable from the input features, in this case, those who are likely to dafault on their loan repayments.\n",
    "\n",
    "### Conclusion\n",
    "While this task proved to be rather challenging, it was a great experience working with large volume datasets with largely imbalanced target variables. There are many different approaches that can be explored in these situations such as oversampling or undersampling, but one of the biggest factors in our progress has been thoughtful feature engineering and advanced modeling techniques such as hyperparameter tuning.\n",
    "\n",
    "As a result of our final model, we were able to achieve an AUC score of **78.425%** which was ~**1.6%** lower than the top public score at the time of the competition.\n",
    "\n",
    "I think it is valuable to reflect on opportunities that we had when building our models. First, I think the model training would have likely yielded better results if we eliminated outliers in our dataset earlier in the EDA process before determining the features. Second, with several datasets we noticed a large volume of categorical variables; our use of OneHotEncoding would cause several of these features to not even be considered due to dimensionality concerns of our dataset. Our final model included a total of 199 features (including OneHot Encoding), and the model from the week prior resulted in 1% less AUC score with half the amount of features. With the goal of parsimony in mind, reducing the number of features would likely be a greater benefit in the long run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5aeb63",
   "metadata": {
    "papermill": {
     "duration": 0.007916,
     "end_time": "2024-05-04T19:14:39.758274",
     "exception": false,
     "start_time": "2024-05-04T19:14:39.750358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Submission Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e0867",
   "metadata": {
    "papermill": {
     "duration": 0.00795,
     "end_time": "2024-05-04T19:14:39.774433",
     "exception": false,
     "start_time": "2024-05-04T19:14:39.766483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries\n",
    "\n",
    "Change as needed. Once completed, remove un-needed libraries and remove this comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c4618c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:14:39.792872Z",
     "iopub.status.busy": "2024-05-04T19:14:39.792481Z",
     "iopub.status.idle": "2024-05-04T19:14:42.197670Z",
     "shell.execute_reply": "2024-05-04T19:14:42.196410Z"
    },
    "papermill": {
     "duration": 2.417572,
     "end_time": "2024-05-04T19:14:42.200354",
     "exception": false,
     "start_time": "2024-05-04T19:14:39.782782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b31cf",
   "metadata": {
    "papermill": {
     "duration": 0.00791,
     "end_time": "2024-05-04T19:14:42.216747",
     "exception": false,
     "start_time": "2024-05-04T19:14:42.208837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Preprocessor and Model\n",
    "\n",
    "change cells below to most recent model etc. and remove this comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a0adb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:14:42.235892Z",
     "iopub.status.busy": "2024-05-04T19:14:42.235339Z",
     "iopub.status.idle": "2024-05-04T19:14:42.348045Z",
     "shell.execute_reply": "2024-05-04T19:14:42.347071Z"
    },
    "papermill": {
     "duration": 0.125616,
     "end_time": "2024-05-04T19:14:42.350459",
     "exception": false,
     "start_time": "2024-05-04T19:14:42.224843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = joblib.load('/kaggle/input/hcdr-model-v6/HCDR_preprocessor_06.joblib')\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.load_model('/kaggle/input/hcdr-model-v6/xgb_model_v6.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f30ed",
   "metadata": {
    "papermill": {
     "duration": 0.008086,
     "end_time": "2024-05-04T19:14:42.367017",
     "exception": false,
     "start_time": "2024-05-04T19:14:42.358931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Test Data and Supporting Data\n",
    "\n",
    "Load other datasets as necessary, this is a placeholder from week 2 model Remove comment when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a43f5f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:14:42.385142Z",
     "iopub.status.busy": "2024-05-04T19:14:42.384516Z",
     "iopub.status.idle": "2024-05-04T19:15:53.495052Z",
     "shell.execute_reply": "2024-05-04T19:15:53.494066Z"
    },
    "papermill": {
     "duration": 71.122453,
     "end_time": "2024-05-04T19:15:53.497687",
     "exception": false,
     "start_time": "2024-05-04T19:14:42.375234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_test = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\n",
    "prev_app = pd.read_csv('/kaggle/input/home-credit-default-risk/previous_application.csv')\n",
    "pos_cash = pd.read_csv('/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv')\n",
    "install_pmts = pd.read_csv('/kaggle/input/home-credit-default-risk/installments_payments.csv')\n",
    "cc_bal = pd.read_csv('/kaggle/input/home-credit-default-risk/credit_card_balance.csv')\n",
    "bureau = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea949b",
   "metadata": {
    "papermill": {
     "duration": 0.008128,
     "end_time": "2024-05-04T19:15:53.514684",
     "exception": false,
     "start_time": "2024-05-04T19:15:53.506556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "The goal in this section is to combine the test features with the relevant test features from our supporting datasets. We need the same features in the test dataset that our model was trained with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f8375c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:15:53.534323Z",
     "iopub.status.busy": "2024-05-04T19:15:53.533695Z",
     "iopub.status.idle": "2024-05-04T19:18:49.031020Z",
     "shell.execute_reply": "2024-05-04T19:18:49.030054Z"
    },
    "papermill": {
     "duration": 175.519617,
     "end_time": "2024-05-04T19:18:49.042628",
     "exception": false,
     "start_time": "2024-05-04T19:15:53.523011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 2.54 s, total: 2min 56s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Previous Application\n",
    "prev_app['CONTRACT_REFUSED_IND'] = (prev_app['NAME_CONTRACT_STATUS'] == 'Refused').astype(int)\n",
    "prev_app['PROD_COMB_IND'] = prev_app['PRODUCT_COMBINATION'].isin(['Cash','POS mobile with interest','Card Street','Cash Street: high','Cash X-Sell: high']).astype(int)\n",
    "\n",
    "prev_app.drop(columns={'NAME_CONTRACT_STATUS','PRODUCT_COMBINATION'}, inplace = True)\n",
    "\n",
    "prev_app_agg_type = {\n",
    "    'SK_ID_PREV' : 'count',\n",
    "    'AMT_APPLICATION' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_CREDIT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'RATE_DOWN_PAYMENT' : ['mean', 'min', 'max', 'median'],\n",
    "    'RATE_INTEREST_PRIMARY' : ['mean', 'min', 'max', 'median'],\n",
    "    'RATE_INTEREST_PRIVILEGED' : ['mean', 'min', 'max', 'median'],\n",
    "    'CONTRACT_REFUSED_IND' : ['median', 'count'],\n",
    "    'PROD_COMB_IND' : ['median', 'count']\n",
    "\n",
    "}\n",
    "\n",
    "prev_app_agg = prev_app.groupby('SK_ID_CURR').agg(prev_app_agg_type).reset_index()\n",
    "\n",
    "prev_app_agg.columns = ['_'.join(col).strip() for col in prev_app_agg.columns.values]\n",
    "\n",
    "for col in prev_app_agg.columns[1:]:\n",
    "    prev_app_agg.rename(columns = {col : 'PREV_'+col}, inplace = True)\n",
    "    \n",
    "prev_app_agg.rename(columns = {'SK_ID_CURR_' : 'SK_ID_CURR'}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# POS Cash\n",
    "pos_cash.drop(columns=('NAME_CONTRACT_STATUS'), inplace = True)\n",
    "\n",
    "pos_agg_type = {\n",
    "    'SK_ID_PREV' : 'count',\n",
    "    'MONTHS_BALANCE' : ['mean', 'min', 'max', 'median'],\n",
    "    'CNT_INSTALMENT' : ['mean', 'min', 'max', 'median'],\n",
    "    'CNT_INSTALMENT_FUTURE' : ['mean', 'min', 'max', 'median'],\n",
    "    'SK_DPD' : ['mean', 'min', 'max', 'median'],\n",
    "    'SK_DPD_DEF' : ['mean', 'min', 'max', 'median'],\n",
    "}\n",
    "\n",
    "pos_cash_agg = pos_cash.groupby('SK_ID_CURR').agg(pos_agg_type).reset_index()\n",
    "\n",
    "pos_cash_agg.columns = ['_'.join(col).strip() for col in pos_cash_agg.columns.values]\n",
    "\n",
    "pos_cash_agg['INSTAL_RATIO'] = (pos_cash_agg['CNT_INSTALMENT_mean'] / np.where(pos_cash_agg['CNT_INSTALMENT_FUTURE_mean'] != 0, pos_cash_agg['CNT_INSTALMENT_FUTURE_mean'], 1)).fillna(0)\n",
    "\n",
    "for col in pos_cash_agg.columns[1:]:\n",
    "    pos_cash_agg.rename(columns = {col : 'POS_'+col}, inplace = True)\n",
    "    \n",
    "pos_cash_agg.fillna(0, inplace = True)\n",
    "\n",
    "pos_cash_agg.rename(columns = {'SK_ID_CURR_' : 'SK_ID_CURR'}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Credit Card Balance\n",
    "cc_bal['USAGE_RATIO'] = (cc_bal['AMT_BALANCE'] / np.where(cc_bal['AMT_CREDIT_LIMIT_ACTUAL'] != 0 , cc_bal['AMT_CREDIT_LIMIT_ACTUAL'],1)).fillna(0)\n",
    "cc_bal['INSTALL_MATURE_AMT'] = (cc_bal['AMT_BALANCE'] / np.where(cc_bal['CNT_INSTALMENT_MATURE_CUM'] != 0 , cc_bal['CNT_INSTALMENT_MATURE_CUM'],1)).fillna(0)\n",
    "\n",
    "cc_agg_type = {\n",
    "    'SK_ID_PREV' : 'count',\n",
    "    'MONTHS_BALANCE' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_BALANCE' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_DRAWINGS_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_DRAWINGS_OTHER_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_DRAWINGS_POS_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_INST_MIN_REGULARITY' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_PAYMENT_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_RECEIVABLE_PRINCIPAL' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_RECIVABLE' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'AMT_TOTAL_RECEIVABLE' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'CNT_DRAWINGS_ATM_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'CNT_DRAWINGS_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'CNT_DRAWINGS_OTHER_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'CNT_DRAWINGS_POS_CURRENT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'CNT_INSTALMENT_MATURE_CUM' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'SK_DPD' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'SK_DPD_DEF' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'USAGE_RATIO' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "    'INSTALL_MATURE_AMT' : ['sum', 'mean', 'min', 'max', 'median'],\n",
    "}\n",
    "\n",
    "cc_bal_agg = cc_bal.groupby('SK_ID_CURR').agg(cc_agg_type).reset_index()\n",
    "\n",
    "cc_bal_agg.columns = ['_'.join(col).strip() for col in cc_bal_agg.columns.values]\n",
    "\n",
    "for col in cc_bal_agg.columns[1:]:\n",
    "    cc_bal_agg.rename(columns = {col : 'CC_'+col}, inplace = True)\n",
    "\n",
    "cc_bal_agg.fillna(0, inplace = True)\n",
    "\n",
    "cc_bal_agg.rename(columns = {'SK_ID_CURR_' : 'SK_ID_CURR'}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Installments Payments\n",
    "install_pmts['DAYS_PMT_DIFF'] = (install_pmts['DAYS_ENTRY_PAYMENT'] - install_pmts['DAYS_INSTALMENT']).fillna(0)\n",
    "install_pmts['ON_TIME_COUNT'] = np.where(install_pmts['DAYS_PMT_DIFF'] <= 0,1,0)\n",
    "\n",
    "inst_agg_type = {\n",
    "    'SK_ID_PREV' : 'count',\n",
    "    'NUM_INSTALMENT_VERSION' : ['mean','min','max','median'],\n",
    "    'NUM_INSTALMENT_NUMBER' : ['mean','min','max','median'],\n",
    "    'DAYS_INSTALMENT' : ['mean','min','max','median'],\n",
    "    'DAYS_ENTRY_PAYMENT' : ['mean','min','max','median'],\n",
    "    'AMT_INSTALMENT' : ['mean','min','max','median'],\n",
    "    'AMT_PAYMENT' : ['mean','min','max','median'],\n",
    "    'DAYS_PMT_DIFF' : ['mean','min','max','median'],\n",
    "    'ON_TIME_COUNT' : ['sum','mean','min','max','median'],\n",
    "}\n",
    "\n",
    "inst_pmts_agg = install_pmts.groupby('SK_ID_CURR').agg(inst_agg_type).reset_index()\n",
    "\n",
    "inst_pmts_agg.columns = ['_'.join(col).strip() for col in inst_pmts_agg.columns.values]\n",
    "\n",
    "for col in inst_pmts_agg.columns[1:]:\n",
    "    inst_pmts_agg.rename(columns = {col : 'INST_'+col}, inplace = True)\n",
    "\n",
    "inst_pmts_agg['INST_ON_TIME_RATIO'] = (inst_pmts_agg['INST_ON_TIME_COUNT_sum'] / np.where(inst_pmts_agg['INST_NUM_INSTALMENT_NUMBER_max'] != 0 ,inst_pmts_agg['INST_NUM_INSTALMENT_NUMBER_max'],1)).fillna(0)\n",
    "inst_pmts_agg['INST_MEAN_PAY_INSTAL_RATIO'] = (inst_pmts_agg['INST_AMT_PAYMENT_mean'] / np.where(inst_pmts_agg['INST_AMT_INSTALMENT_mean'] != 0 ,inst_pmts_agg['INST_AMT_INSTALMENT_mean'],1)).fillna(0)\n",
    "\n",
    "inst_pmts_agg.fillna(0, inplace = True)\n",
    "\n",
    "inst_pmts_agg.rename(columns = {'SK_ID_CURR_' : 'SK_ID_CURR'}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bureau\n",
    "bureau_agg_type = {\n",
    "    'SK_ID_BUREAU': 'count',\n",
    "    'CREDIT_CURRENCY': lambda x: x.mode()[0] if not x.mode().empty else 'N/A',\n",
    "    'DAYS_CREDIT' : ['sum','mean','min','max','median'],\n",
    "    'CREDIT_DAY_OVERDUE': ['sum','mean','min','max','median'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['sum','mean','min','max','median'],\n",
    "    'DAYS_ENDDATE_FACT': ['sum','mean','min','max','median'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['sum','mean','min','max','median'],\n",
    "    'CNT_CREDIT_PROLONG': ['sum','mean','min','max','median'],\n",
    "    'AMT_CREDIT_SUM': ['sum','mean','min','max','median'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['sum','mean','min','max','median'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['sum','mean','min','max','median'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['sum','mean','min','max','median'],\n",
    "    'CREDIT_TYPE': lambda x: x.mode()[0] if not x.mode().empty else np.nan,\n",
    "    'DAYS_CREDIT_UPDATE': ['sum','mean','min','max','median'],\n",
    "    'AMT_ANNUITY': ['sum','mean','min','max','median']   \n",
    "}\n",
    "\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg(bureau_agg_type).reset_index()\n",
    "\n",
    "bureau_agg.columns = ['_'.join(col).strip() for col in bureau_agg.columns.values]\n",
    "\n",
    "for col in bureau_agg.columns[1:]:\n",
    "    bureau_agg.rename(columns = {col : 'BUR_'+col}, inplace = True)\n",
    "    \n",
    "bureau_agg.rename(columns = {\n",
    "    'BUR_CREDIT_CURRENCY_<lambda>' : 'BUR_CREDIT_CURRENCY_mode',\n",
    "    'BUR_CREDIT_TYPE_<lambda>' : 'BUR_CREDIT_TYPE_mode'\n",
    "},inplace = True)\n",
    "\n",
    "bureau_agg['BUR_DEBT_RATIO'] = bureau_agg['BUR_AMT_CREDIT_SUM_DEBT_sum'] / np.where(bureau_agg['BUR_AMT_CREDIT_SUM_sum'] != 0, bureau_agg['BUR_AMT_CREDIT_SUM_sum'], 1)\n",
    "\n",
    "for col in bureau_agg.columns:\n",
    "    if bureau_agg[col].dtype in (int,float):\n",
    "        bureau_agg[col].fillna(0, inplace = True)\n",
    "        \n",
    "bureau_agg.rename(columns = {'SK_ID_CURR_' : 'SK_ID_CURR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03d42b",
   "metadata": {
    "papermill": {
     "duration": 0.008442,
     "end_time": "2024-05-04T19:18:49.059871",
     "exception": false,
     "start_time": "2024-05-04T19:18:49.051429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reduce Memory / Create Test Dataset\n",
    "\n",
    "Each aggregated dataset is stored in a new dataframe. Considering the size of some of these datasets, it is best to remove the source entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5deacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:49.079816Z",
     "iopub.status.busy": "2024-05-04T19:18:49.079401Z",
     "iopub.status.idle": "2024-05-04T19:18:49.201335Z",
     "shell.execute_reply": "2024-05-04T19:18:49.200222Z"
    },
    "papermill": {
     "duration": 0.135215,
     "end_time": "2024-05-04T19:18:49.203873",
     "exception": false,
     "start_time": "2024-05-04T19:18:49.068658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del install_pmts\n",
    "del prev_app\n",
    "del pos_cash\n",
    "del cc_bal\n",
    "del bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10b9a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:49.222596Z",
     "iopub.status.busy": "2024-05-04T19:18:49.222178Z",
     "iopub.status.idle": "2024-05-04T19:18:49.712325Z",
     "shell.execute_reply": "2024-05-04T19:18:49.711525Z"
    },
    "papermill": {
     "duration": 0.502062,
     "end_time": "2024-05-04T19:18:49.714614",
     "exception": false,
     "start_time": "2024-05-04T19:18:49.212552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Merge Complete\n",
      "2 Merges Complete\n",
      "3 Merges Complete\n",
      "4 Merges Complete\n",
      "All 5 Merges Completed\n",
      "CPU times: user 481 ms, sys: 4.03 ms, total: 485 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test = app_test.merge(prev_app_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "print('1 Merge Complete')\n",
    "\n",
    "test = test.merge(pos_cash_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "print('2 Merges Complete')\n",
    "\n",
    "test = test.merge(cc_bal_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "print('3 Merges Complete')\n",
    "\n",
    "test = test.merge(inst_pmts_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "print('4 Merges Complete')\n",
    "\n",
    "test = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "print('All 5 Merges Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d9126",
   "metadata": {
    "papermill": {
     "duration": 0.008414,
     "end_time": "2024-05-04T19:18:49.731793",
     "exception": false,
     "start_time": "2024-05-04T19:18:49.723379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Post-Merge Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573dcb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:49.750915Z",
     "iopub.status.busy": "2024-05-04T19:18:49.750454Z",
     "iopub.status.idle": "2024-05-04T19:18:50.670867Z",
     "shell.execute_reply": "2024-05-04T19:18:50.669688Z"
    },
    "papermill": {
     "duration": 0.933428,
     "end_time": "2024-05-04T19:18:50.673713",
     "exception": false,
     "start_time": "2024-05-04T19:18:49.740285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## application test\n",
    "test['LOG_INCOME_CREDIT_RATIO'] = np.log((test['AMT_INCOME_TOTAL'] / np.where(test['AMT_CREDIT'] != 0 ,test['AMT_CREDIT'],1)).fillna(0))\n",
    "test['CREDIT_GOODS_RATIO'] = (test['AMT_CREDIT'] / np.where(test['AMT_GOODS_PRICE'] != 0 ,test['AMT_GOODS_PRICE'],1)).fillna(0)\n",
    "test['CODE_GENDER'] = test['CODE_GENDER'].isin(['F']).astype(int)\n",
    "test['FLAG_OWN_CAR'] = test['FLAG_OWN_CAR'].isin(['Y']).astype(int)\n",
    "test['LOG_AMT_INCOME_TOTAL'] = np.log(test['AMT_INCOME_TOTAL'])\n",
    "test['CREDIT_ANNUITY_RATIO'] = (test['AMT_CREDIT'] / np.where(test['AMT_ANNUITY'] != 0 ,test['AMT_ANNUITY'],1)).fillna(0)\n",
    "\n",
    "## application train + previous application\n",
    "test['PREV_GOODS_APPSUM'] = test['AMT_GOODS_PRICE'] / np.where(test['PREV_AMT_APPLICATION_sum'] != 0, test['PREV_AMT_APPLICATION_sum'], 1)\n",
    "test['PREV_GOODS_CREDSUM'] = test['AMT_GOODS_PRICE'] / np.where(test['PREV_AMT_CREDIT_sum'] != 0, test['PREV_AMT_CREDIT_sum'], 1)\n",
    "test['PREV_CREDIT_APPSUM'] = test['AMT_CREDIT'] / np.where(test['PREV_AMT_APPLICATION_sum'] != 0, test['PREV_AMT_APPLICATION_sum'], 1)\n",
    "test['LOG_PREV_INC_APPSUM'] = np.log(test['AMT_INCOME_TOTAL'] / np.where(test['PREV_AMT_APPLICATION_sum'] != 0, test['PREV_AMT_APPLICATION_sum'], 1))\n",
    "test['PREV_INC_CREDSUM'] = test['AMT_INCOME_TOTAL'] / np.where(test['PREV_AMT_CREDIT_sum'] != 0, test['PREV_AMT_CREDIT_sum'], 1)\n",
    "\n",
    "## application train + POS CASH\n",
    "test['POS_INST_F_GOODS'] = test['AMT_GOODS_PRICE'] / np.where(test['POS_CNT_INSTALMENT_FUTURE_mean'] != 0, test['POS_CNT_INSTALMENT_FUTURE_mean'], 1)\n",
    "\n",
    "## application train + Installments Payments\n",
    "test['INST_GOODS_PMT'] = np.log(abs(test['AMT_GOODS_PRICE'] / np.where(test['INST_AMT_PAYMENT_mean'] != 0, test['INST_AMT_PAYMENT_mean'], 1)))\n",
    "\n",
    "## application train +  Credit Card Balance\n",
    "test['CC_GOODS_INST_MAT'] = test['AMT_GOODS_PRICE'] / np.where(test['CC_INSTALL_MATURE_AMT_mean'] != 0, test['CC_INSTALL_MATURE_AMT_mean'], 1)\n",
    "\n",
    "## application train + bureau\n",
    "test['BUR_CRED_ANN_RATIO'] = test['BUR_AMT_CREDIT_SUM_sum'] / np.where(test['BUR_AMT_ANNUITY_sum'] != 0, test['BUR_AMT_ANNUITY_sum'], 1)\n",
    "\n",
    "\n",
    "\n",
    "# Fix Indicators being converted to floats post-merge\n",
    "test['PREV_CONTRACT_REFUSED_IND_median'].fillna(0, inplace = True)\n",
    "test['PREV_PROD_COMB_IND_median'].fillna(0, inplace = True)\n",
    "\n",
    "for column in test.columns:\n",
    "    if test[column].dtype == float:\n",
    "        unique_values = test[column].unique()\n",
    "        if set(unique_values) == {0.0, 1.0}:\n",
    "            test[column] = test[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64591ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:50.692430Z",
     "iopub.status.busy": "2024-05-04T19:18:50.692075Z",
     "iopub.status.idle": "2024-05-04T19:18:51.161703Z",
     "shell.execute_reply": "2024-05-04T19:18:51.160540Z"
    },
    "papermill": {
     "duration": 0.481775,
     "end_time": "2024-05-04T19:18:51.164045",
     "exception": false,
     "start_time": "2024-05-04T19:18:50.682270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 199)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = preprocessor.transform(test)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78fde7f",
   "metadata": {
    "papermill": {
     "duration": 0.009065,
     "end_time": "2024-05-04T19:18:51.182139",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.173074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75bf7d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:51.201639Z",
     "iopub.status.busy": "2024-05-04T19:18:51.201265Z",
     "iopub.status.idle": "2024-05-04T19:18:51.388478Z",
     "shell.execute_reply": "2024-05-04T19:18:51.387657Z"
    },
    "papermill": {
     "duration": 0.199645,
     "end_time": "2024-05-04T19:18:51.390940",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.191295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs = model.predict_proba(X_test)\n",
    "\n",
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007178a8",
   "metadata": {
    "papermill": {
     "duration": 0.00882,
     "end_time": "2024-05-04T19:18:51.409633",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.400813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79156e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:51.428613Z",
     "iopub.status.busy": "2024-05-04T19:18:51.428220Z",
     "iopub.status.idle": "2024-05-04T19:18:51.465180Z",
     "shell.execute_reply": "2024-05-04T19:18:51.464134Z"
    },
    "papermill": {
     "duration": 0.049212,
     "end_time": "2024-05-04T19:18:51.467478",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.418266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET\n",
       "0      100001     0.5\n",
       "1      100005     0.5\n",
       "2      100013     0.5\n",
       "3      100028     0.5\n",
       "4      100038     0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('/kaggle/input/home-credit-default-risk/sample_submission.csv')\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda3898a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:51.488192Z",
     "iopub.status.busy": "2024-05-04T19:18:51.487310Z",
     "iopub.status.idle": "2024-05-04T19:18:51.491775Z",
     "shell.execute_reply": "2024-05-04T19:18:51.491035Z"
    },
    "papermill": {
     "duration": 0.016655,
     "end_time": "2024-05-04T19:18:51.493627",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.476972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.TARGET = test_probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2fa976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T19:18:51.513689Z",
     "iopub.status.busy": "2024-05-04T19:18:51.513030Z",
     "iopub.status.idle": "2024-05-04T19:18:51.642853Z",
     "shell.execute_reply": "2024-05-04T19:18:51.641276Z"
    },
    "papermill": {
     "duration": 0.142828,
     "end_time": "2024-05-04T19:18:51.645564",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.502736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afcb6ce",
   "metadata": {
    "papermill": {
     "duration": 0.0093,
     "end_time": "2024-05-04T19:18:51.664590",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.655290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Model Score and Closing Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7efc98",
   "metadata": {
    "papermill": {
     "duration": 0.008991,
     "end_time": "2024-05-04T19:18:51.682836",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.673845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Private Score: **78.274%**\n",
    "## Public Score: **78.425%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d08816",
   "metadata": {
    "papermill": {
     "duration": 0.009206,
     "end_time": "2024-05-04T19:18:51.701229",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.692023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Final Notes\n",
    "\n",
    "During this capstone project I was able to get hands on experience with large datasets, and was sucessfully able to identify loan applicants who are at a high risk of defaulting on their loans. Using the ROC AUC score, we achieved scores as high as 78.425% which is a calculated measure between sensitivity and specificity. The ROC AUC score is primarily a measure that accounts for true positives and false positives.\n",
    "\n",
    "In addition to experience building complex models in python, I was also able to experience more complex tasks like aggregating supplementary data, testing new models, as well as various methods of hyperparameter tuning. My primary take-away from this project is the importance of developing comprehensive exploratory data analysis to understand key attributes of our dataset. Exploratory data analysis and feature engineering are responsible for the majority of our progress each week, however, on some occasions it was worthwhile exploring various transformations for our features to imporve our model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971cb5b",
   "metadata": {
    "papermill": {
     "duration": 0.009034,
     "end_time": "2024-05-04T19:18:51.719283",
     "exception": false,
     "start_time": "2024-05-04T19:18:51.710249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 860599,
     "sourceId": 9120,
     "sourceType": "competition"
    },
    {
     "datasetId": 4934847,
     "sourceId": 8307969,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 255.48523,
   "end_time": "2024-05-04T19:18:52.350011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-04T19:14:36.864781",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
